# Debug Configuration for Prompt Alchemy
# This extends docker-config.yaml with debug settings

# Provider configurations with debug/verbose modes
providers:
  openai:
    model: "o4-mini"
    base_url: "https://api.openai.com/v1"
    timeout: 120  # Increased for debug
    debug: true
    log_requests: true
    log_responses: true
    retry_attempts: 1  # Reduce retries to see errors faster
    
  anthropic:
    model: "claude-3-5-sonnet-20241022"
    timeout: 120
    debug: true
    log_requests: true
    log_responses: true
    retry_attempts: 1
    
  google:
    model: "gemini-1.5-pro"
    timeout: 120
    debug: true
    log_requests: true
    log_responses: true
    retry_attempts: 1
    
  openrouter:
    model: "openrouter/auto"
    base_url: "https://openrouter.ai/api/v1"
    timeout: 120
    debug: true
    log_requests: true
    log_responses: true
    retry_attempts: 1
    
  ollama:
    base_url: "http://host.docker.internal:11434"
    model: "gemma2:2b"
    timeout: 300  # Much longer for local models
    debug: true
    log_requests: true
    log_responses: true
    
  grok:
    model: "grok-2-1212"
    base_url: "https://api.x.ai/v1"
    timeout: 120
    debug: true
    log_requests: true
    log_responses: true
    retry_attempts: 1

# Phase configurations
phases:
  prima-materia:
    provider: "anthropic"
  solutio:
    provider: "openai"
  coagulatio:
    provider: "anthropic"

# Generation settings with debug
generation:
  default_temperature: 0.7
  default_max_tokens: 2000
  default_count: 3
  use_parallel: false  # Disable parallel for clearer logs
  default_embedding_model: "text-embedding-3-small"
  default_embedding_dimensions: 1536
  log_generation_steps: true
  log_phase_transitions: true
  trace_template_rendering: true

# Embedding settings
embeddings:
  provider: "openai"
  model: "text-embedding-3-small"
  dimensions: 1536
  auto_migrate_legacy: true
  log_embedding_requests: true
  log_similarity_scores: true

# Data storage with debug
data_dir: "/app/data"
database:
  path: "/app/data/prompts.db"
  log_queries: true
  log_migrations: true
  trace_transactions: true
  enable_wal: true  # Write-ahead logging for better debugging

# Maximum debug logging
log_level: "trace"
logging:
  format: "json"  # Structured logging
  include_caller: true
  include_stacktrace: true
  timestamp_format: "RFC3339Nano"
  
  # Log destinations
  outputs:
    - type: "file"
      path: "/app/logs/prompt-alchemy.log"
      rotate: true
      max_size: "100MB"
      max_backups: 10
    - type: "stdout"
      format: "console"  # Human readable for docker logs
      
  # Component-specific logging
  components:
    engine:
      level: "trace"
      log_file: "/app/logs/engine.log"
    providers:
      level: "trace"
      log_file: "/app/logs/providers.log"
    storage:
      level: "trace"
      log_file: "/app/logs/storage.log"
    http:
      level: "trace"
      log_file: "/app/logs/http.log"
      log_requests: true
      log_responses: true
      log_headers: true
    templates:
      level: "trace"
      log_file: "/app/logs/templates.log"
    ranking:
      level: "trace"
      log_file: "/app/logs/ranking.log"
    learning:
      level: "trace"
      log_file: "/app/logs/learning.log"

# Performance monitoring
metrics:
  enabled: true
  export_interval: "10s"
  include_runtime_metrics: true
  include_provider_metrics: true
  include_database_metrics: true
  log_file: "/app/logs/metrics.log"

# Learning settings with debug
learning:
  enabled: true
  log_training_steps: true
  log_weight_updates: true
  trace_feedback_processing: true

# Ranking configuration with debug
ranking:
  weights:
    temperature: 0.2
    token: 0.2
    semantic: 0.3
    length: 0.1
    historical: 0.2
  log_scoring_details: true
  trace_weight_calculations: true

# Debug features
debug:
  # API debug endpoints
  enable_debug_endpoints: true
  enable_pprof: true  # Go profiling
  
  # Request/Response logging
  log_all_requests: true
  log_all_responses: true
  log_request_bodies: true
  log_response_bodies: true
  
  # Slow query logging
  slow_query_threshold: "100ms"
  log_slow_queries: true
  
  # Memory debugging
  log_memory_stats: true
  memory_stats_interval: "30s"
  
  # Panic recovery with full stack
  recover_panics: true
  log_panic_stack: true
  
  # Template debugging
  template_debug_mode: true
  reload_templates_on_change: true
  
  # Provider debugging
  mock_provider_responses: false
  log_provider_selection: true
  trace_provider_fallback: true
  
  # Feature flags for testing
  features:
    disable_rate_limiting: true
    disable_caching: false  # Keep caching to test cache behavior
    force_sequential_processing: true
    enable_request_id_tracking: true